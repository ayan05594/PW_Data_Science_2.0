{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "-x8474dIn0Me"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Q1. What is Min-Max scaling, and how is it used in data preprocessing? Provide an example to illustrate its application.\n",
        "- **Min-Max Scaling** is a feature scaling technique where the values of a feature are normalized to a specific range, typically [0, 1]. The formula for Min-Max scaling is:\n",
        "  X_scaled = (X - X_min) / (X_max - X_min)\n",
        "  Where:\n",
        "    X = the value of the feature\n",
        "    X_min = the minimum value of the feature\n",
        "    X_max = the maximum value of the feature\n",
        "\n",
        "  Example:\n",
        "  Dataset: [1, 5, 10, 15, 20]\n",
        "  Min-Max scaling to the range [0, 1]:\n",
        "  1 -> (1-1)/(20-1) = 0\n",
        "  5 -> (5-1)/(20-1) = 0.21\n",
        "  10 -> (10-1)/(20-1) = 0.47\n",
        "  15 -> (15-1)/(20-1) = 0.74\n",
        "  20 -> (20-1)/(20-1) = 1\n",
        "\n",
        "Q2. What is the Unit Vector technique in feature scaling, and how does it differ from Min-Max scaling? Provide an example to illustrate its application.\n",
        "- **Unit Vector Scaling** (also known as **Normalization**) scales the feature vector such that its magnitude (Euclidean norm) becomes 1. The formula for unit vector normalization is:\n",
        "  X_scaled = X / ||X||\n",
        "  Where ||X|| is the Euclidean norm (magnitude) of the vector, calculated as √(X1² + X2² + ... + Xn²).\n",
        "\n",
        "  Difference:\n",
        "  - Min-Max scaling scales data to a fixed range (e.g., [0, 1]), while Unit Vector scaling focuses on scaling the data based on its vector magnitude.\n",
        "  - Min-Max scaling is used when you want to preserve the relative relationships of data, whereas Unit Vector scaling normalizes the entire vector without regard to the range of individual values.\n",
        "\n",
        "  Example:\n",
        "  Dataset: [1, 2, 3]\n",
        "  Magnitude of vector: √(1² + 2² + 3²) = √14 ≈ 3.74\n",
        "  Unit Vector scaling: [1/3.74, 2/3.74, 3/3.74] ≈ [0.267, 0.534, 0.801]\n",
        "\n",
        "Q3. What is PCA (Principal Component Analysis), and how is it used in dimensionality reduction? Provide an example to illustrate its application.\n",
        "- **PCA** is a statistical technique used for dimensionality reduction by transforming the data into a set of orthogonal (uncorrelated) axes called **principal components**. These components capture the directions of maximum variance in the data.\n",
        "  - PCA reduces the number of features by projecting the original features onto fewer principal components, retaining most of the variance.\n",
        "\n",
        "  Example:\n",
        "  Given a dataset with features [Height, Weight]:\n",
        "  1. Calculate the covariance matrix of the dataset.\n",
        "  2. Find the eigenvalues and eigenvectors of the covariance matrix.\n",
        "  3. Sort the eigenvectors by eigenvalue and select the top k eigenvectors (principal components).\n",
        "  4. Project the data onto the selected principal components for dimensionality reduction.\n",
        "\n",
        "Q4. What is the relationship between PCA and Feature Extraction, and how can PCA be used for Feature Extraction? Provide an example to illustrate this concept.\n",
        "- **PCA** is often used for **Feature Extraction** because it identifies the most informative directions (principal components) in a dataset, effectively transforming the original features into new, uncorrelated features that summarize the data.\n",
        "  - PCA can reduce redundancy and highlight the most important patterns in the data by extracting features that account for the maximum variance.\n",
        "\n",
        "  Example:\n",
        "  In a dataset with features [Height, Weight, Age], PCA could identify that the first principal component explains most of the variance in the data, and the second component might capture less important information. By selecting these components, we reduce the dataset to just two features that capture most of the variation in the data.\n",
        "\n",
        "Q5. You are working on a project to build a recommendation system for a food delivery service. The dataset contains features such as price, rating, and delivery time. Explain how you would use Min-Max scaling to preprocess the data.\n",
        "- **Min-Max scaling** is useful in this scenario to ensure that all features (price, rating, and delivery time) are on a comparable scale. Since each of these features may have a different range, scaling them to a common range (e.g., [0, 1]) ensures that no feature dominates the others in the model.\n",
        "  - For each feature (price, rating, and delivery time), we apply Min-Max scaling individually, transforming the values into the desired range.\n",
        "\n",
        "Q6. You are working on a project to build a model to predict stock prices. The dataset contains many features, such as company financial data and market trends. Explain how you would use PCA to reduce the dimensionality of the dataset.\n",
        "- **PCA** can be applied to reduce the number of features in the stock price prediction dataset, which likely contains correlated features such as various financial indicators and market trends.\n",
        "  - First, normalize the dataset (e.g., using Min-Max scaling) to ensure that each feature has equal importance.\n",
        "  - Apply PCA to identify the principal components that capture the majority of the variance in the data.\n",
        "  - Select the top k principal components that explain most of the variance and use them as the new feature set for the model.\n",
        "\n",
        "Q7. For a dataset containing the following values: [1, 5, 10, 15, 20], perform Min-Max scaling to transform the values to a range of -1 to 1.\n",
        "- Min-Max scaling formula:\n",
        "  X_scaled = 2 * ((X - X_min) / (X_max - X_min)) - 1\n",
        "  Min value: 1, Max value: 20\n",
        "  1 -> 2 * ((1 - 1) / (20 - 1)) - 1 = -1\n",
        "  5 -> 2 * ((5 - 1) / (20 - 1)) - 1 = -0.7368\n",
        "  10 -> 2 * ((10 - 1) / (20 - 1)) - 1 = -0.4737\n",
        "  15 -> 2 * ((15 - 1) / (20 - 1)) - 1 = -0.2105\n",
        "  20 -> 2 * ((20 - 1) / (20 - 1)) - 1 = 1\n",
        "\n",
        "Q8. For a dataset containing the following features: [height, weight, age, gender, blood pressure], perform Feature Extraction using PCA. How many principal components would you choose to retain, and why?\n",
        "- To perform PCA, first normalize the dataset, and then compute the eigenvalues and eigenvectors. After calculating the principal components, I would choose the number of components to retain based on the explained variance ratio.\n",
        "  - Generally, you want to retain enough principal components to explain at least 80-90% of the total variance in the data.\n",
        "  - The number of components chosen depends on the cumulative explained variance; for example, if the first three principal components explain 85% of the variance, I would retain three components for further analysis.\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "vpO8gL65hH7G",
        "outputId": "4791e599-9d77-49ca-bb82-983fba168f19"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nQ1. What is Min-Max scaling, and how is it used in data preprocessing? Provide an example to illustrate its application.\\n- **Min-Max Scaling** is a feature scaling technique where the values of a feature are normalized to a specific range, typically [0, 1]. The formula for Min-Max scaling is:\\n  X_scaled = (X - X_min) / (X_max - X_min)\\n  Where:\\n    X = the value of the feature\\n    X_min = the minimum value of the feature\\n    X_max = the maximum value of the feature\\n\\n  Example:\\n  Dataset: [1, 5, 10, 15, 20]\\n  Min-Max scaling to the range [0, 1]:\\n  1 -> (1-1)/(20-1) = 0\\n  5 -> (5-1)/(20-1) = 0.21\\n  10 -> (10-1)/(20-1) = 0.47\\n  15 -> (15-1)/(20-1) = 0.74\\n  20 -> (20-1)/(20-1) = 1\\n\\nQ2. What is the Unit Vector technique in feature scaling, and how does it differ from Min-Max scaling? Provide an example to illustrate its application.\\n- **Unit Vector Scaling** (also known as **Normalization**) scales the feature vector such that its magnitude (Euclidean norm) becomes 1. The formula for unit vector normalization is:\\n  X_scaled = X / ||X||\\n  Where ||X|| is the Euclidean norm (magnitude) of the vector, calculated as √(X1² + X2² + ... + Xn²).\\n\\n  Difference:\\n  - Min-Max scaling scales data to a fixed range (e.g., [0, 1]), while Unit Vector scaling focuses on scaling the data based on its vector magnitude.\\n  - Min-Max scaling is used when you want to preserve the relative relationships of data, whereas Unit Vector scaling normalizes the entire vector without regard to the range of individual values.\\n\\n  Example:\\n  Dataset: [1, 2, 3]\\n  Magnitude of vector: √(1² + 2² + 3²) = √14 ≈ 3.74\\n  Unit Vector scaling: [1/3.74, 2/3.74, 3/3.74] ≈ [0.267, 0.534, 0.801]\\n\\nQ3. What is PCA (Principal Component Analysis), and how is it used in dimensionality reduction? Provide an example to illustrate its application.\\n- **PCA** is a statistical technique used for dimensionality reduction by transforming the data into a set of orthogonal (uncorrelated) axes called **principal components**. These components capture the directions of maximum variance in the data.\\n  - PCA reduces the number of features by projecting the original features onto fewer principal components, retaining most of the variance.\\n  \\n  Example:\\n  Given a dataset with features [Height, Weight]:\\n  1. Calculate the covariance matrix of the dataset.\\n  2. Find the eigenvalues and eigenvectors of the covariance matrix.\\n  3. Sort the eigenvectors by eigenvalue and select the top k eigenvectors (principal components).\\n  4. Project the data onto the selected principal components for dimensionality reduction.\\n\\nQ4. What is the relationship between PCA and Feature Extraction, and how can PCA be used for Feature Extraction? Provide an example to illustrate this concept.\\n- **PCA** is often used for **Feature Extraction** because it identifies the most informative directions (principal components) in a dataset, effectively transforming the original features into new, uncorrelated features that summarize the data.\\n  - PCA can reduce redundancy and highlight the most important patterns in the data by extracting features that account for the maximum variance.\\n\\n  Example:\\n  In a dataset with features [Height, Weight, Age], PCA could identify that the first principal component explains most of the variance in the data, and the second component might capture less important information. By selecting these components, we reduce the dataset to just two features that capture most of the variation in the data.\\n\\nQ5. You are working on a project to build a recommendation system for a food delivery service. The dataset contains features such as price, rating, and delivery time. Explain how you would use Min-Max scaling to preprocess the data.\\n- **Min-Max scaling** is useful in this scenario to ensure that all features (price, rating, and delivery time) are on a comparable scale. Since each of these features may have a different range, scaling them to a common range (e.g., [0, 1]) ensures that no feature dominates the others in the model.\\n  - For each feature (price, rating, and delivery time), we apply Min-Max scaling individually, transforming the values into the desired range.\\n\\nQ6. You are working on a project to build a model to predict stock prices. The dataset contains many features, such as company financial data and market trends. Explain how you would use PCA to reduce the dimensionality of the dataset.\\n- **PCA** can be applied to reduce the number of features in the stock price prediction dataset, which likely contains correlated features such as various financial indicators and market trends.\\n  - First, normalize the dataset (e.g., using Min-Max scaling) to ensure that each feature has equal importance.\\n  - Apply PCA to identify the principal components that capture the majority of the variance in the data.\\n  - Select the top k principal components that explain most of the variance and use them as the new feature set for the model.\\n\\nQ7. For a dataset containing the following values: [1, 5, 10, 15, 20], perform Min-Max scaling to transform the values to a range of -1 to 1.\\n- Min-Max scaling formula:\\n  X_scaled = 2 * ((X - X_min) / (X_max - X_min)) - 1\\n  Min value: 1, Max value: 20\\n  1 -> 2 * ((1 - 1) / (20 - 1)) - 1 = -1\\n  5 -> 2 * ((5 - 1) / (20 - 1)) - 1 = -0.7368\\n  10 -> 2 * ((10 - 1) / (20 - 1)) - 1 = -0.4737\\n  15 -> 2 * ((15 - 1) / (20 - 1)) - 1 = -0.2105\\n  20 -> 2 * ((20 - 1) / (20 - 1)) - 1 = 1\\n\\nQ8. For a dataset containing the following features: [height, weight, age, gender, blood pressure], perform Feature Extraction using PCA. How many principal components would you choose to retain, and why?\\n- To perform PCA, first normalize the dataset, and then compute the eigenvalues and eigenvectors. After calculating the principal components, I would choose the number of components to retain based on the explained variance ratio.\\n  - Generally, you want to retain enough principal components to explain at least 80-90% of the total variance in the data.\\n  - The number of components chosen depends on the cumulative explained variance; for example, if the first three principal components explain 85% of the variance, I would retain three components for further analysis.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4c3LAGCSn2ct"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}