{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Q1. What is Web Scraping? Why is it Used? Give three areas where Web Scraping is used to get data.\n",
        "# Web Scraping:\n",
        "# - Web scraping is the process of extracting data from websites.\n",
        "# - It involves fetching a website's content and parsing it to retrieve specific information.\n",
        "#\n",
        "# Why is it Used?:\n",
        "# - To automate data collection from websites.\n",
        "# - To gather large-scale data for analysis, research, or machine learning models.\n",
        "#\n",
        "# Areas Where Web Scraping is Used:\n",
        "# 1. E-commerce: To compare prices or track competitor products.\n",
        "# 2. Real Estate: To gather property listings, prices, and market trends.\n",
        "# 3. Social Media: To analyze trends, hashtags, or user sentiment.\n",
        "\n",
        "# Q2. What are the different methods used for Web Scraping?\n",
        "# 1. Using APIs: Many websites provide APIs to access data in a structured format (e.g., JSON).\n",
        "# 2. HTML Parsing: Libraries like Beautiful Soup or lxml are used to parse HTML and extract specific elements.\n",
        "# 3. Automated Tools: Tools like Selenium or Puppeteer are used for dynamic websites requiring JavaScript execution.\n",
        "# 4. Scrapy Framework: A powerful Python framework for large-scale web scraping projects.\n",
        "\n",
        "# Q3. What is Beautiful Soup? Why is it used?\n",
        "# Beautiful Soup:\n",
        "# - A Python library for parsing HTML and XML documents.\n",
        "# - It allows for easy navigation, searching, and modification of the parse tree.\n",
        "#\n",
        "# Why is it Used?:\n",
        "# - To extract specific data from HTML content.\n",
        "# - Simplifies parsing of complex HTML structures.\n",
        "\n",
        "# Q4. Why is Flask used in this Web Scraping project?\n",
        "# Flask is used to:\n",
        "# - Create a web interface for users to interact with the scraping tool.\n",
        "# - Allow users to provide input (e.g., URLs or keywords) and view the extracted data.\n",
        "# - Serve the scraped data via API endpoints or as rendered web pages.\n",
        "\n",
        "# Q5. Write the names of AWS services used in this project. Also, explain the use of each service.\n",
        "# 1. Amazon EC2:\n",
        "#    - Used to host and run the Flask application and web scraping script.\n",
        "# 2. Amazon S3:\n",
        "#    - Used for storing scraped data or results in a secure and scalable manner.\n",
        "# 3. AWS Lambda:\n",
        "#    - Used for serverless execution of scraping scripts on a schedule or triggered by events.\n",
        "# 4. Amazon RDS:\n",
        "#    - Used to store structured data in a database (e.g., MySQL or PostgreSQL) for long-term access.\n",
        "# 5. AWS CloudWatch:\n",
        "#    - Used for monitoring the performance and logging the activities of the scraping application.\n",
        "\n",
        "# The combination of these services enables scalable, efficient, and reliable web scraping.\n"
      ],
      "metadata": {
        "id": "pFj9XPWIz06t"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}