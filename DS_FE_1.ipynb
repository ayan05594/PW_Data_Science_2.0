{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "```python\n",
        "\"\"\"\n",
        "Q1: What are missing values in a dataset? Why is it essential to handle missing values? Name some algorithms that are not affected by missing values.\n",
        "- Missing values refer to the absence of data for certain attributes or observations in a dataset. Missing data can occur for various reasons such as errors in data collection, system malfunctions, or human errors.\n",
        "- Handling missing values is crucial because they can lead to biased models, inaccurate predictions, or reduced statistical power. Most machine learning algorithms require complete data for training.\n",
        "- Algorithms like decision trees, random forests, and k-nearest neighbors (KNN) are less sensitive to missing values as they can handle missing data through imputation or by splitting the data accordingly.\n",
        "\n",
        "Q2: List down techniques used to handle missing data. Give an example of each with python code.\n",
        "1. **Deletion Methods**:\n",
        "   - Removing rows with missing values:\n",
        "   ```python\n",
        "   import pandas as pd\n",
        "   data = pd.read_csv(\"dataset.csv\")\n",
        "   data_cleaned = data.dropna()  # Drop rows with any missing values\n",
        "   ```\n",
        "\n",
        "2. **Imputation Methods**:\n",
        "   - Filling missing values with mean, median, or mode:\n",
        "   ```python\n",
        "   data['column'].fillna(data['column'].mean(), inplace=True)  # Mean imputation\n",
        "   ```\n",
        "\n",
        "3. **Using Algorithms that Handle Missing Data**:\n",
        "   - Some algorithms like Random Forests handle missing data naturally by considering available features during the split.\n",
        "   \n",
        "4. **Forward/Backward Filling**:\n",
        "   - Forward fill missing values using the previous value:\n",
        "   ```python\n",
        "   data['column'].fillna(method='ffill', inplace=True)  # Forward fill\n",
        "   ```\n",
        "\n",
        "Q3: Explain imbalanced data. What will happen if imbalanced data is not handled?\n",
        "- Imbalanced data occurs when one class (target variable) has significantly more samples than the other class. This leads to models being biased toward the majority class.\n",
        "- If imbalanced data is not handled, the model may predict the majority class most of the time, leading to poor performance on the minority class, which is often more important.\n",
        "\n",
        "Q4: What are Up-sampling and Down-sampling? Explain with an example when up-sampling and down-sampling are required.\n",
        "- **Up-sampling** involves increasing the number of samples in the minority class by replicating or generating synthetic samples.\n",
        "- **Down-sampling** involves reducing the number of samples in the majority class to balance the dataset.\n",
        "  \n",
        "Example for up-sampling:\n",
        "```python\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "ros = RandomOverSampler(sampling_strategy='minority')\n",
        "X_resampled, y_resampled = ros.fit_resample(X, y)\n",
        "```\n",
        "\n",
        "Example for down-sampling:\n",
        "```python\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "rus = RandomUnderSampler(sampling_strategy='majority')\n",
        "X_resampled, y_resampled = rus.fit_resample(X, y)\n",
        "```\n",
        "\n",
        "Q5: What is data Augmentation? Explain SMOTE.\n",
        "- **Data Augmentation** is the process of artificially increasing the size of the training dataset by generating new, synthetic data points based on the original data.\n",
        "- **SMOTE (Synthetic Minority Over-sampling Technique)** creates synthetic samples for the minority class by interpolating between existing samples.\n",
        "\n",
        "Example of SMOTE:\n",
        "```python\n",
        "from imblearn.over_sampling import SMOTE\n",
        "smote = SMOTE()\n",
        "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
        "```\n",
        "\n",
        "Q6: What are outliers in a dataset? Why is it essential to handle outliers?\n",
        "- **Outliers** are data points that significantly deviate from the other observations in the dataset. They can be caused by measurement errors or rare events.\n",
        "- Outliers can distort statistical analyses, affect model performance, and lead to inaccurate predictions. They should be handled carefully, either by removing them or transforming them.\n",
        "\n",
        "Q7: You are working on a project that requires analyzing customer data. However, you notice that some of the data is missing. What are some techniques you can use to handle the missing data in your analysis?\n",
        "- Techniques include deletion (dropping rows or columns), imputation (mean, median, mode), or using models that handle missing data like decision trees or k-nearest neighbors.\n",
        "\n",
        "Q8: You are working with a large dataset and find that a small percentage of the data is missing. What are some strategies you can use to determine if the missing data is missing at random or if there is a pattern to the missing data?\n",
        "- Use techniques like **Missingness Patterns** (e.g., missing data heatmaps), and conduct tests like Little's MCAR (Missing Completely at Random) test to determine if missing data has any inherent pattern.\n",
        "\n",
        "Q9: Suppose you are working on a medical diagnosis project and find that the majority of patients in the dataset do not have the condition of interest, while a small percentage do. What are some strategies you can use to evaluate the performance of your machine learning model on this imbalanced dataset?\n",
        "- Use techniques like **precision, recall, F1-score**, and **ROC-AUC** to evaluate model performance on imbalanced datasets. Additionally, resampling techniques such as SMOTE, random over-sampling, or down-sampling can be applied.\n",
        "\n",
        "Q10: When attempting to estimate customer satisfaction for a project, you discover that the dataset is unbalanced, with the bulk of customers reporting being satisfied. What methods can you employ to balance the dataset and down-sample the majority class?\n",
        "- You can use **down-sampling** to reduce the number of satisfied customers, or use techniques like SMOTE to up-sample the minority class of dissatisfied customers.\n",
        "\n",
        "Q11: You discover that the dataset is unbalanced with a low percentage of occurrences while working on a project that requires you to estimate the occurrence of a rare event. What methods can you employ to balance the dataset and up-sample the minority class?\n",
        "- Use **SMOTE** or other up-sampling techniques to generate synthetic samples for the minority class. Alternatively, use **class weights** to assign higher importance to the minority class during model training.\n",
        "\"\"\"\n",
        "```"
      ],
      "metadata": {
        "id": "7nV0-aAUNtaw"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vpO8gL65hH7G"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}